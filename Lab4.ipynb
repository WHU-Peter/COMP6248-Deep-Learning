{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab4.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNQawQZEXzRzDkKgeCbyonV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WHU-Peter/COMP6248-Deep-Learning/blob/master/Lab4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXxpbOg65XLP"
      },
      "source": [
        "# Execute this code block to install dependencies when running on colab\n",
        "try:\n",
        "    import torch\n",
        "except:\n",
        "    from os.path import exists\n",
        "    from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "    platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "    cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "    accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "    !pip install -q http://download.pytorch.org/whl/{accelerator}/torch-1.0.0-{platform}-linux_x86_64.whl torchvision\n",
        "\n",
        "try: \n",
        "    import torchbearer\n",
        "except:\n",
        "    !pip install torchbearer\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import MNIST\n",
        "import torchbearer\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bmkBsLZ5bdH"
      },
      "source": [
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "torch.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "np.random.seed(seed)\n",
        "\n",
        "# flatten 28*28 images to a 784 vector for each image\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),  # convert to tensor\n",
        "    transforms.Lambda(lambda x: x.view(-1))  # flatten into vector\n",
        "])\n",
        "\n",
        "# load data\n",
        "trainset = MNIST(\".\", train=True, download=True, transform=transform)\n",
        "testset = MNIST(\".\", train=False, download=True, transform=transform)\n",
        "\n",
        "# create data loaders\n",
        "trainloader = DataLoader(trainset, batch_size=128, shuffle=True)\n",
        "testloader = DataLoader(testset, batch_size=128, shuffle=True)\n",
        "\n",
        "# define baseline model\n",
        "class BaselineModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(BaselineModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size) \n",
        "        self.fc2 = nn.Linear(hidden_size, num_classes)  \n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = F.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        if not self.training:\n",
        "            out = F.softmax(out, dim=1)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxiuhcC29_K1",
        "outputId": "057faf1d-f20e-4573-a403-2e71c9605b5a"
      },
      "source": [
        "print(torch.cuda.list_gpu_processes())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda driver can't be loaded, is cuda enabled?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S06WBVXPMeA0"
      },
      "source": [
        "# trainloader1 = DataLoader(trainset, batch_size=60000, shuffle=True)\n",
        "# testloader1 = DataLoader(testset, batch_size=10000, shuffle=True)\n",
        "# train_data = 0\n",
        "# train_labels = 0\n",
        "# test_data = 0\n",
        "# test_labels = 0\n",
        "\n",
        "# for inputs, labels in trainloader1:\n",
        "#   train_data = inputs\n",
        "#   train_labels = labels\n",
        "\n",
        "# for inputs, labels in testloader1:\n",
        "#   test_data = inputs\n",
        "#   test_labels = labels\n",
        "\n",
        "# train_data = train_data.to(device)\n",
        "# train_labels = train_labels.to(device)\n",
        "# test_data = test_data.to(device)\n",
        "# test_labels = test_labels.to(device)\n",
        "# print(train_data.shape)\n",
        "# print(train_labels.shape)\n",
        "# print(test_data.shape)\n",
        "# print(test_labels.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mXJnap75s4P"
      },
      "source": [
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "# device = \"cpu\"\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "def training(model, epoches=10):\n",
        "  # define the loss function and the optimiser\n",
        "  optimiser = optim.Adam(model.parameters())\n",
        "  model = model.to(device)\n",
        "\n",
        "  train_loss_trace = np.zeros(epoches+1)\n",
        "  train_accuracy_trace = np.zeros(epoches+1)\n",
        "  test_loss_trace = np.zeros(epoches+1)\n",
        "  test_accuracy_trace = np.zeros(epoches+1)\n",
        "  # the epoch loop\n",
        "  train_loss, train_accuracy, test_loss, test_accuracy = test(model)\n",
        "  train_loss_trace[0] = train_loss\n",
        "  train_accuracy_trace[0] = train_accuracy\n",
        "  test_loss_trace[0] = test_loss\n",
        "  test_accuracy_trace[0] = test_accuracy\n",
        "  print(\"训练开始\")\n",
        "  print(train_loss, train_accuracy, test_loss, test_accuracy)\n",
        "  for epoch in range(epoches):\n",
        "      running_loss = 0.0\n",
        "      for data in trainloader:\n",
        "          # get the inputs\n",
        "          inputs, labels = data\n",
        "          inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "          # zero the parameter gradients\n",
        "          optimiser.zero_grad()\n",
        "\n",
        "          # forward + loss + backward + optimise (update weights)\n",
        "          outputs = model(inputs)\n",
        "          loss = loss_function(outputs, labels)\n",
        "          loss.backward()\n",
        "          optimiser.step()\n",
        "      train_loss, train_accuracy, test_loss, test_accuracy = test(model)\n",
        "      train_loss_trace[epoch+1] = train_loss\n",
        "      train_accuracy_trace[epoch+1] = train_accuracy\n",
        "      test_loss_trace[epoch+1] = test_loss\n",
        "      test_accuracy_trace[epoch+1] = test_accuracy\n",
        "      print(\"训练完成一次\")\n",
        "      print(train_loss, train_accuracy, test_loss, test_accuracy)\n",
        "  fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(10,10))\n",
        "  ax[0,0].plot(train_loss_trace, c='m')\n",
        "  ax[0,0].grid(True)\n",
        "  ax[0,0].set_xlabel(\"Iteration\", fontsize=14)\n",
        "  ax[0,0].set_ylabel(\"Train_Loss\", fontsize=14)\n",
        "  ax[0,0].set_title(\"Traing Set\", fontsize=14)\n",
        "  ax[0,1].plot(test_loss_trace, c='r')\n",
        "  ax[0,1].grid(True)\n",
        "  ax[0,1].set_xlabel(\"Iteration\", fontsize=14)\n",
        "  ax[0,1].set_ylabel(\"Test_Loss\", fontsize=14)\n",
        "  ax[0,1].set_title(\"Test Set\", fontsize=14)\n",
        "  ax[1,0].plot(train_accuracy_trace, c='m')\n",
        "  ax[1,0].grid(True)\n",
        "  ax[1,0].set_xlabel(\"Iteration\", fontsize=14)\n",
        "  ax[1,0].set_ylabel(\"Train_Accuracy\", fontsize=14)\n",
        "  ax[1,0].set_title(\"Traing Set\", fontsize=14)\n",
        "  ax[1,1].plot(test_accuracy_trace, c='r')\n",
        "  ax[1,1].grid(True)\n",
        "  ax[1,1].set_xlabel(\"Iteration\", fontsize=14)\n",
        "  ax[1,1].set_ylabel(\"Test_Accuracy\", fontsize=14)\n",
        "  ax[1,1].set_title(\"Test Set\", fontsize=14)\n",
        "  plt.show()\n",
        "\n",
        "def test(model):\n",
        "  model.eval()\n",
        "  # Compute the model accuracy on the test set\n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "  train_loss = 0\n",
        "  train_correct = 0\n",
        "  train_total = 0\n",
        "  for data in trainloader:\n",
        "    # get the inputs\n",
        "    inputs, labels = data\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "    outputs = model(inputs)\n",
        "    train_loss += loss_function(outputs, labels)\n",
        "    prediction = torch.argmax(outputs, 1)\n",
        "    train_correct += (prediction == labels).sum().float()\n",
        "    train_total += len(labels)\n",
        "  train_accuracy = (100.0 * train_correct) / train_total\n",
        "  \n",
        "  test_loss = 0\n",
        "  test_correct = 0\n",
        "  test_total = 0\n",
        "  for data in testloader:\n",
        "    # get the inputs\n",
        "    inputs, labels = data\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "    outputs = model(inputs)\n",
        "    test_loss += loss_function(outputs, labels)\n",
        "    prediction = torch.argmax(outputs, 1)\n",
        "    test_correct += (prediction == labels).sum().float()\n",
        "    test_total += len(labels)\n",
        "  test_accuracy = (100.0 * test_correct) / test_total\n",
        "  model.train()\n",
        "  return train_loss, train_accuracy, test_loss, test_accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wodzw-Ed6qGV"
      },
      "source": [
        "model1 = BaselineModel(784, 784, 10)\n",
        "training(model1)\n",
        "\n",
        "model2 = BaselineModel(784, 10000, 10)\n",
        "training(model2)\n",
        "\n",
        "model3 = BaselineModel(784, 50000, 10)\n",
        "training(model3)\n",
        "\n",
        "model4 = BaselineModel(784, 100000, 10)\n",
        "training(model4)\n",
        "\n",
        "model5 = BaselineModel(784, 500000, 10)\n",
        "training(model5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZ6JNgS7C6Nw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}